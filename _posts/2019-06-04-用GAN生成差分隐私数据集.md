---
layout:     post
title:      用GAN生成差分隐私数据集
subtitle:   ICLR 2018-rej
date:       2019-06-04
author:     BY
header-img: img/post-bg-re-vs-ng2.jpg
catalog: true
tags:
    - GAN
	- 差分隐私
	- 证明
---

> 今天看了 Generating Differentially Private Datasets Using GANS，明天要讨论。老师不知道从哪里挖出了这篇被拒了的文，
研究的主题和我们最近的工作非常相关，而且证明非常有趣，大致地看了一下文章的结构觉得没啥问题，但是看评审的comments感觉发现了不一样的视角，
但是他们差分隐私的证明还是值得梳理。可能是学科视角的原因？我一学统计的看这种文章总是觉得有些奇怪。原文☞https://openreview.net/forum?id=rJv4XWZA- 


# 架构
生成器：从数据中学习数据的概率分布p(data)，抽样生成数据
判别器：增加一个高斯噪音层，使输出的数据实现差分隐私效果，从而使生成器的权重也能实现差分隐私。

流程：敏感数据集通过判别器，向前传递，加上噪音，训练生成器，生成器产生新数据集。

# 如何实现差分隐私

## 记号

- \pi: 高斯噪音层
- x_\pi,x_\pi^\prime: \pi层的输入
- \hat{y},\hat{y}^\prime = N(X),N(X): 神经元网络最后一层输出

## 引理1 
> 如果高斯噪音层的输入保证X,X^\prime的邻接性质，且层的输出保证(\epsilon, \delta)差分隐私



## 定理1（向前传递）
>如果一个确定的（没有dropout）向前传递神经元网络的高斯噪音层保证（\epsilon, \delta)差分隐私性质，那么
这个神经元网络的输出\hat{y}也可以保证（\epsilon, \delta)差分隐私。

## 定理2（向后传递）
>如果一个向前传递网络的输出\hat{y}保证（\epsilon, \delta)差分隐私，那么在第i次梯度下降的时候，权重更新
\omega_X^{(i)}也可以保证（\epsilon, \delta)差分隐私。


## 结论(GAN)
>给定一个Gan，生成器的隐私约束和判别器（带有隐私保护层）的隐私保护水平是一样的。

## 定理3（私人标签）
>如果一个向前传递网络N的输出\hat{y}保证（\epsilon_1, \delta_1)差分隐私，训练标签
\tilder{y}保证（\epsilon_2, \delta_2)差分隐私，那么在第i次梯度下降的时候，权重更新
\omega_X^{(i)}也可以保证（\epsilon_1+\epsilon_2, \delta_1+\delta_2)差分隐私。

在标签的训练上，让数据X和监督标签y用不同的隐私保护机制M_1和M_2，那么可以使用基础
**顺序组合定理**来获得隐私保护水平。

# 不足之处


